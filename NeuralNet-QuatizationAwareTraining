{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()\n",
    "data = '/data/vectors/data0625/'\n",
    "path = directory + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wp.txt\n",
      "nowp.txt\n",
      "silence.txt\n"
     ]
    }
   ],
   "source": [
    "data = np.empty((0,fft+1))\n",
    "for fname in ['wp.txt','nowp.txt','silence.txt']:\n",
    "    print(fname)\n",
    "    with open(path+fname) as f:\n",
    "        dat = np.genfromtxt(f, delimiter=',', dtype='int', \n",
    "                            invalid_raise=False)\n",
    "        if fname.startswith('w'):\n",
    "            dat[:,-1] = 2\n",
    "        elif fname.startswith('no'):\n",
    "            dat[:,-1] = 1\n",
    "        else:\n",
    "            dat[:,-1] = 0 ## silence\n",
    "    data = np.concatenate([data,dat],axis=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 2049)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample: 784\n",
      "number of sample: 261\n",
      "number of sample: 263\n"
     ]
    }
   ],
   "source": [
    "train_len = int(.6*(data_set.shape[0]))\n",
    "val_len = int(.2*(data_set.shape[0]))\n",
    "np.random.seed(21)\n",
    "np.random.shuffle(data_set)\n",
    "trainNN, valNN, testNN = np.split(data_set, [train_len,train_len+val_len])\n",
    "\n",
    "X_trainNN = trainNN[:,:-1]\n",
    "y_trainNN = trainNN[:,-1]\n",
    "X_valNN = valNN[:,:-1]\n",
    "y_valNN = valNN[:,-1]\n",
    "X_testNN = testNN[:,:-1]\n",
    "y_testNN = testNN[:,-1]\n",
    "\n",
    "print('number of sample: '+ str(len(X_trainNN)))\n",
    "print('number of sample: '+ str(len(y_valNN)))\n",
    "print('number of sample: '+ str(len(y_testNN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(fft,)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(12, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfmot.quantization.keras.quantize_model(model)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = './models/TFLite/0625/threeClass/QAW_Integer.h5'\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min', \n",
    "                                   verbose=0, \n",
    "                                   patience=10)\n",
    "mc = keras.callbacks.ModelCheckpoint(filepath=best_model_path, \n",
    "                                     monitor='val_acc', \n",
    "                                     mode='max', \n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7011 - acc: 0.6773 - val_loss: 0.4866 - val_acc: 0.7663\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3850 - acc: 0.8329 - val_loss: 0.4015 - val_acc: 0.8008\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2717 - acc: 0.9082 - val_loss: 0.2458 - val_acc: 0.9272\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1830 - acc: 0.9490 - val_loss: 0.1867 - val_acc: 0.9425\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1203 - acc: 0.9694 - val_loss: 0.1667 - val_acc: 0.9349\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0829 - acc: 0.9872 - val_loss: 0.1352 - val_acc: 0.9464\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0562 - acc: 0.9936 - val_loss: 0.1189 - val_acc: 0.9617\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0299 - acc: 0.9974 - val_loss: 0.1044 - val_acc: 0.9540\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 0.9579\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9579\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9579\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1760 - val_acc: 0.9234\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9655\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9617\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9579\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1374 - val_acc: 0.9617\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9617\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 9.4904e-04 - acc: 1.0000 - val_loss: 0.1456 - val_acc: 0.9617\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trainNN,\n",
    "                    y_trainNN, \n",
    "                    epochs=500,\n",
    "                    batch_size=40,\n",
    "                    validation_data=(X_valNN, y_valNN),\n",
    "                    callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 746us/step - loss: 0.1277 - acc: 0.9658\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_testNN, y_testNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  0,  0],\n",
       "       [ 0, 77,  4],\n",
       "       [ 0,  5, 80]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_testNN, np.argmax(model.predict(X_testNN), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 2048)              3         \n",
      "_________________________________________________________________\n",
      "quant_dropout (QuantizeWrapp (None, 2048)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 32)                65573     \n",
      "_________________________________________________________________\n",
      "quant_dropout_1 (QuantizeWra (None, 32)                1         \n",
      "_________________________________________________________________\n",
      "quant_dense_1 (QuantizeWrapp (None, 12)                401       \n",
      "_________________________________________________________________\n",
      "quant_dense_2 (QuantizeWrapp (None, 3)                 44        \n",
      "=================================================================\n",
      "Total params: 66,023\n",
      "Trainable params: 66,003\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Integer Post-Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sailaj01/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/sailaj01/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /var/folders/7m/7gjw27ys7vs7gkgvbdgx5rjc0000gn/T/tmponejfkb5/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './models/TFLite/0625/threeClass/QAW_Quantized.tflite'\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model is 844 KB\n",
      "Quantized model is 69 KB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(best_model_path)\n",
    "print(\"Original model is %d KB\" % int(model_size/1000))\n",
    "\n",
    "quantized_model_size = os.path.getsize(filename)\n",
    "print(\"Quantized model is %d KB\" % int(quantized_model_size/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Converted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input_1',\n",
       "  'index': 0,\n",
       "  'shape': array([   1, 2048], dtype=int32),\n",
       "  'shape_signature': array([  -1, 2048], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 1,\n",
       "  'shape': array([32], dtype=int32),\n",
       "  'shape_signature': array([32], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.00012086482456652448, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00012086], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 2,\n",
       "  'shape': array([12], dtype=int32),\n",
       "  'shape_signature': array([12], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0007195599609985948, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00071956], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_2/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 3,\n",
       "  'shape': array([3], dtype=int32),\n",
       "  'shape_signature': array([3], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0004757487040478736, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00047575], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quantize_layer/MovingAvgQuantize/FakeQuantWithMinMaxVars;sequential/quantize_layer/MovingAvgQuantize/FakeQuantWithMinMaxVars/ReadVariableOp/resource;sequential/quantize_layer/MovingAvgQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1/resource',\n",
       "  'index': 4,\n",
       "  'shape': array([   1, 2048], dtype=int32),\n",
       "  'shape_signature': array([  -1, 2048], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.1352684050798416, -97),\n",
       "  'quantization_parameters': {'scales': array([0.1352684], dtype=float32),\n",
       "   'zero_points': array([-97], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense/MatMul;sequential/quant_dense/LastValueQuant/FakeQuantWithMinMaxVars',\n",
       "  'index': 5,\n",
       "  'shape': array([  32, 2048], dtype=int32),\n",
       "  'shape_signature': array([  32, 2048], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0008935185032896698, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00089352], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense/Relu;sequential/quant_dense/BiasAdd',\n",
       "  'index': 6,\n",
       "  'shape': array([ 1, 32], dtype=int32),\n",
       "  'shape_signature': array([-1, 32], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.21378090977668762, -108),\n",
       "  'quantization_parameters': {'scales': array([0.21378091], dtype=float32),\n",
       "   'zero_points': array([-108], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/MatMul;sequential/quant_dense_1/LastValueQuant/FakeQuantWithMinMaxVars',\n",
       "  'index': 7,\n",
       "  'shape': array([12, 32], dtype=int32),\n",
       "  'shape_signature': array([12, 32], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0033658756874501705, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00336588], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_1/Relu;sequential/quant_dense_1/BiasAdd',\n",
       "  'index': 8,\n",
       "  'shape': array([ 1, 12], dtype=int32),\n",
       "  'shape_signature': array([-1, 12], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.09493309259414673, -84),\n",
       "  'quantization_parameters': {'scales': array([0.09493309], dtype=float32),\n",
       "   'zero_points': array([-84], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_2/MatMul;sequential/quant_dense_2/LastValueQuant/FakeQuantWithMinMaxVars',\n",
       "  'index': 9,\n",
       "  'shape': array([ 3, 12], dtype=int32),\n",
       "  'shape_signature': array([ 3, 12], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.005011410918086767, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00501141], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_2/BiasAdd',\n",
       "  'index': 10,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.05347698926925659, 14),\n",
       "  'quantization_parameters': {'scales': array([0.05347699], dtype=float32),\n",
       "   'zero_points': array([14], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/quant_dense_2/Softmax',\n",
       "  'index': 11,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00390625, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity',\n",
       "  'index': 12,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=filename) \n",
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using Full-Quantized TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "scale, zero_points = input_details['quantization']\n",
    "\n",
    "tflite_predict = []\n",
    "tflite_predict_class = []\n",
    "for vector in X_testNN:\n",
    "    #input_data = np.array(vector.reshape(input_details['shape'])/scale + zero_points, dtype=np.int8)\n",
    "    input_data = np.array(vector.reshape(input_details['shape']), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details['index'], input_data)\n",
    "    \n",
    "    interpreter.invoke()    \n",
    "    prediction = interpreter.get_tensor(output_details['index'])\n",
    "    tflite_predict.append(prediction)\n",
    "    tflite_predict_class.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of both the model and its optimized version are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  0,  0],\n",
       "       [ 0, 77,  4],\n",
       "       [ 0,  5, 80]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_testNN, tflite_predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
