{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()\n",
    "data = '/data/vectors/data0625/'\n",
    "path = directory + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wp.txt\n",
      "nowp.txt\n",
      "silence.txt\n"
     ]
    }
   ],
   "source": [
    "data = np.empty((0,fft+1))\n",
    "for fname in ['wp.txt','nowp.txt','silence.txt']:\n",
    "    print(fname)\n",
    "    with open(path+fname) as f:\n",
    "        dat = np.genfromtxt(f, delimiter=',', dtype='int', \n",
    "                            invalid_raise=False)\n",
    "        if fname.startswith('w'):\n",
    "            dat[:,-1] = 2\n",
    "        elif fname.startswith('no'):\n",
    "            dat[:,-1] = 1\n",
    "        else:\n",
    "            dat[:,-1] = 0 ## silence\n",
    "    data = np.concatenate([data,dat],axis=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 2049)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample: 784\n",
      "number of sample: 261\n",
      "number of sample: 263\n"
     ]
    }
   ],
   "source": [
    "train_len = int(.6*(data_set.shape[0]))\n",
    "val_len = int(.2*(data_set.shape[0]))\n",
    "np.random.seed(21)\n",
    "np.random.shuffle(data_set)\n",
    "trainNN, valNN, testNN = np.split(data_set, [train_len,train_len+val_len])\n",
    "\n",
    "X_trainNN = trainNN[:,:-1]\n",
    "y_trainNN = trainNN[:,-1]\n",
    "X_valNN = valNN[:,:-1]\n",
    "y_valNN = valNN[:,-1]\n",
    "X_testNN = testNN[:,:-1]\n",
    "y_testNN = testNN[:,-1]\n",
    "\n",
    "print('number of sample: '+ str(len(X_trainNN)))\n",
    "print('number of sample: '+ str(len(y_valNN)))\n",
    "print('number of sample: '+ str(len(y_testNN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(fft,)))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dropout(.1))\n",
    "model.add(keras.layers.Dense(12, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = './models/TFLite/0625/threeClass/NoQAW.h5'\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                   mode='min', \n",
    "                                   verbose=0, \n",
    "                                   patience=10)\n",
    "mc = keras.callbacks.ModelCheckpoint(filepath=best_model_path, \n",
    "                                     monitor='val_acc', \n",
    "                                     mode='max', \n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.6051 - acc: 0.4758 - val_loss: 0.5253 - val_acc: 0.7318\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5732 - acc: 0.7079 - val_loss: 0.4944 - val_acc: 0.6437\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4441 - acc: 0.7462 - val_loss: 0.4341 - val_acc: 0.6897\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4359 - acc: 0.7640 - val_loss: 0.4172 - val_acc: 0.7165\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4224 - acc: 0.7755 - val_loss: 0.3941 - val_acc: 0.7893\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3585 - acc: 0.8253 - val_loss: 0.3519 - val_acc: 0.8506\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3681 - acc: 0.8380 - val_loss: 0.3132 - val_acc: 0.8774\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3103 - acc: 0.8916 - val_loss: 0.2800 - val_acc: 0.8966\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2632 - acc: 0.8954 - val_loss: 0.2336 - val_acc: 0.9042\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2044 - acc: 0.9298 - val_loss: 0.1889 - val_acc: 0.9272\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1685 - acc: 0.9401 - val_loss: 0.1727 - val_acc: 0.9425\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1436 - acc: 0.9490 - val_loss: 0.1559 - val_acc: 0.9425\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1256 - acc: 0.9541 - val_loss: 0.1373 - val_acc: 0.9502\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0863 - acc: 0.9834 - val_loss: 0.1347 - val_acc: 0.9464\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0959 - acc: 0.9630 - val_loss: 0.1178 - val_acc: 0.9502\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0663 - acc: 0.9783 - val_loss: 0.1075 - val_acc: 0.9579\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0530 - acc: 0.9834 - val_loss: 0.1137 - val_acc: 0.9502\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0505 - acc: 0.9834 - val_loss: 0.1040 - val_acc: 0.9579\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0437 - acc: 0.9911 - val_loss: 0.1289 - val_acc: 0.9502\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0477 - acc: 0.9860 - val_loss: 0.1078 - val_acc: 0.9540\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0441 - acc: 0.9834 - val_loss: 0.1593 - val_acc: 0.9349\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0370 - acc: 0.9911 - val_loss: 0.0934 - val_acc: 0.9579\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0372 - acc: 0.9872 - val_loss: 0.0930 - val_acc: 0.9655\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0290 - acc: 0.9936 - val_loss: 0.1025 - val_acc: 0.9617\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 0.9923 - val_loss: 0.1279 - val_acc: 0.9540\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0275 - acc: 0.9872 - val_loss: 0.1048 - val_acc: 0.9579\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0181 - acc: 0.9962 - val_loss: 0.1102 - val_acc: 0.9579\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0263 - acc: 0.9911 - val_loss: 0.1008 - val_acc: 0.9617\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.2173 - val_acc: 0.9234\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.9834 - val_loss: 0.1217 - val_acc: 0.9617\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0235 - acc: 0.9923 - val_loss: 0.0944 - val_acc: 0.9540\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0202 - acc: 0.9911 - val_loss: 0.0935 - val_acc: 0.9617\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0141 - acc: 0.9962 - val_loss: 0.1001 - val_acc: 0.9617\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trainNN,\n",
    "                    y_trainNN, \n",
    "                    epochs=500,\n",
    "                    batch_size=40,\n",
    "                    validation_data=(X_valNN, y_valNN),\n",
    "                    callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 666us/step - loss: 0.0771 - acc: 0.9620\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_testNN, y_testNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  0,  0],\n",
       "       [ 0, 79,  2],\n",
       "       [ 0,  8, 77]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_testNN, np.argmax(model.predict(X_testNN), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 66,003\n",
      "Trainable params: 66,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Integer Post-Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for dat in trainNN: \n",
    "        dat = dat.astype('float32')\n",
    "        yield [dat[:fft]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sailaj01/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/sailaj01/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /var/folders/7m/7gjw27ys7vs7gkgvbdgx5rjc0000gn/T/tmpwcqs9p7v/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# These set the input and output tensors to uint8 (added in r2.3)\n",
    "converter.inference_input_type = tf.int8\n",
    "#converter.inference_output_type = tf.uint8\n",
    "\n",
    "# And this sets the representative dataset so we can quantize the activations\n",
    "converter.representative_dataset = representative_data_gen\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './models/TFLite/0625/threeClass/NoQAW_Quantized.tflite'\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model is 824 KB\n",
      "Quantized model is 68 KB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(best_model_path)\n",
    "print(\"Original model is %d KB\" % int(model_size/1000))\n",
    "\n",
    "quantized_model_size = os.path.getsize(filename)\n",
    "print(\"Quantized model is %d KB\" % int(quantized_model_size/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Converted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input_1',\n",
       "  'index': 0,\n",
       "  'shape': array([   1, 2048], dtype=int32),\n",
       "  'shape_signature': array([  -1, 2048], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.45490196347236633, -128),\n",
       "  'quantization_parameters': {'scales': array([0.45490196], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 1,\n",
       "  'shape': array([32], dtype=int32),\n",
       "  'shape_signature': array([32], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0005456146318465471, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00054561], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_1/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 2,\n",
       "  'shape': array([12], dtype=int32),\n",
       "  'shape_signature': array([12], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0019012941047549248, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00190129], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_2/BiasAdd/ReadVariableOp/resource',\n",
       "  'index': 3,\n",
       "  'shape': array([3], dtype=int32),\n",
       "  'shape_signature': array([3], dtype=int32),\n",
       "  'dtype': numpy.int32,\n",
       "  'quantization': (0.0025823183823376894, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00258232], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense/MatMul',\n",
       "  'index': 4,\n",
       "  'shape': array([  32, 2048], dtype=int32),\n",
       "  'shape_signature': array([  32, 2048], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.0011994114611297846, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00119941], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_1/MatMul',\n",
       "  'index': 5,\n",
       "  'shape': array([12, 32], dtype=int32),\n",
       "  'shape_signature': array([12, 32], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003922671545296907, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392267], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_2/MatMul',\n",
       "  'index': 6,\n",
       "  'shape': array([ 3, 12], dtype=int32),\n",
       "  'shape_signature': array([ 3, 12], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.004713286645710468, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00471329], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense/Relu;sequential/dense/BiasAdd',\n",
       "  'index': 7,\n",
       "  'shape': array([ 1, 32], dtype=int32),\n",
       "  'shape_signature': array([-1, 32], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.4846936762332916, -128),\n",
       "  'quantization_parameters': {'scales': array([0.48469368], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_1/Relu;sequential/dense_1/BiasAdd',\n",
       "  'index': 8,\n",
       "  'shape': array([ 1, 12], dtype=int32),\n",
       "  'shape_signature': array([-1, 12], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.5478805899620056, -128),\n",
       "  'quantization_parameters': {'scales': array([0.5478806], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'sequential/dense_2/BiasAdd',\n",
       "  'index': 9,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.3632339835166931, -119),\n",
       "  'quantization_parameters': {'scales': array([0.36323398], dtype=float32),\n",
       "   'zero_points': array([-119], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity_int8',\n",
       "  'index': 10,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00390625, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([-128], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}},\n",
       " {'name': 'Identity',\n",
       "  'index': 11,\n",
       "  'shape': array([1, 3], dtype=int32),\n",
       "  'shape_signature': array([-1,  3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=filename) \n",
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using Full-Quantized TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "scale, zero_points = input_details['quantization']\n",
    "\n",
    "tflite_predict = []\n",
    "tflite_predict_class = []\n",
    "for vector in X_testNN:\n",
    "    input_data = np.array(vector.reshape(input_details['shape'])/scale + zero_points, dtype=np.int8)\n",
    "    interpreter.set_tensor(input_details['index'], input_data)\n",
    "    \n",
    "    interpreter.invoke()    \n",
    "    prediction = interpreter.get_tensor(output_details['index'])\n",
    "    tflite_predict.append(prediction)\n",
    "    tflite_predict_class.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of both the model and its optimized version are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  0,  0],\n",
       "       [ 0, 79,  2],\n",
       "       [ 0,  8, 77]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_testNN, tflite_predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
